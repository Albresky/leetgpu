//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-36424714
// Cuda compilation tools, release 13.0, V13.0.88
// Based on NVVM 7.0.1
//

.version 9.0
.target sm_89
.address_size 64

	// .globl	_Z10vector_addPKfS0_Pfi

.visible .entry _Z10vector_addPKfS0_Pfi(
	.param .u64 _Z10vector_addPKfS0_Pfi_param_0,
	.param .u64 _Z10vector_addPKfS0_Pfi_param_1,
	.param .u64 _Z10vector_addPKfS0_Pfi_param_2,
	.param .u32 _Z10vector_addPKfS0_Pfi_param_3
)
{
	.reg .pred 	%p<11>;
	.reg .f32 	%f<116>;
	.reg .b32 	%r<59>;
	.reg .b64 	%rd<64>;


	ld.param.u64 	%rd26, [_Z10vector_addPKfS0_Pfi_param_0];
	ld.param.u64 	%rd27, [_Z10vector_addPKfS0_Pfi_param_1];
	ld.param.u64 	%rd28, [_Z10vector_addPKfS0_Pfi_param_2];
	ld.param.u32 	%r26, [_Z10vector_addPKfS0_Pfi_param_3];
	cvta.to.global.u64 	%rd1, %rd28;
	cvta.to.global.u64 	%rd2, %rd27;
	cvta.to.global.u64 	%rd3, %rd26;
	mov.u32 	%r27, %ntid.x;
	mov.u32 	%r28, %ctaid.x;
	mul.lo.s32 	%r1, %r28, %r27;
	mov.u32 	%r2, %tid.x;
	add.s32 	%r3, %r1, %r2;
	mov.u32 	%r29, %nctaid.x;
	mul.lo.s32 	%r4, %r27, %r29;
	shr.s32 	%r30, %r26, 31;
	shr.u32 	%r31, %r30, 30;
	add.s32 	%r32, %r26, %r31;
	shr.s32 	%r5, %r32, 2;
	setp.ge.s32 	%p1, %r3, %r5;
	@%p1 bra 	$L__BB0_7;

	add.s32 	%r33, %r5, %r4;
	add.s32 	%r34, %r3, %r4;
	not.b32 	%r35, %r34;
	add.s32 	%r36, %r33, %r35;
	div.u32 	%r6, %r36, %r4;
	add.s32 	%r37, %r6, 1;
	and.b32  	%r52, %r37, 3;
	setp.eq.s32 	%p2, %r52, 0;
	mov.u32 	%r53, %r3;
	@%p2 bra 	$L__BB0_4;

	mul.wide.s32 	%rd29, %r3, 4;
	shl.b64 	%rd30, %rd29, 2;
	add.s64 	%rd60, %rd2, %rd30;
	mul.wide.s32 	%rd5, %r4, 16;
	add.s64 	%rd59, %rd3, %rd30;
	add.s64 	%rd58, %rd1, %rd30;
	mov.u32 	%r53, %r3;

$L__BB0_3:
	.pragma "nounroll";
	ld.global.nc.v4.f32 	{%f1, %f2, %f3, %f4}, [%rd59];
	ld.global.nc.v4.f32 	{%f9, %f10, %f11, %f12}, [%rd60];
	add.f32 	%f17, %f4, %f12;
	add.f32 	%f18, %f3, %f11;
	add.f32 	%f19, %f2, %f10;
	add.f32 	%f20, %f1, %f9;
	st.global.v4.f32 	[%rd58], {%f20, %f19, %f18, %f17};
	add.s32 	%r53, %r53, %r4;
	add.s64 	%rd60, %rd60, %rd5;
	add.s64 	%rd59, %rd59, %rd5;
	add.s64 	%rd58, %rd58, %rd5;
	add.s32 	%r52, %r52, -1;
	setp.ne.s32 	%p3, %r52, 0;
	@%p3 bra 	$L__BB0_3;

$L__BB0_4:
	setp.lt.u32 	%p4, %r6, 3;
	@%p4 bra 	$L__BB0_7;

	mul.wide.s32 	%rd14, %r4, 16;

$L__BB0_6:
	mul.wide.s32 	%rd31, %r53, 16;
	add.s64 	%rd32, %rd3, %rd31;
	ld.global.nc.v4.f32 	{%f21, %f22, %f23, %f24}, [%rd32];
	add.s64 	%rd33, %rd2, %rd31;
	ld.global.nc.v4.f32 	{%f29, %f30, %f31, %f32}, [%rd33];
	add.s64 	%rd34, %rd1, %rd31;
	add.f32 	%f37, %f24, %f32;
	add.f32 	%f38, %f23, %f31;
	add.f32 	%f39, %f22, %f30;
	add.f32 	%f40, %f21, %f29;
	st.global.v4.f32 	[%rd34], {%f40, %f39, %f38, %f37};
	add.s64 	%rd35, %rd32, %rd14;
	ld.global.nc.v4.f32 	{%f41, %f42, %f43, %f44}, [%rd35];
	add.s64 	%rd36, %rd33, %rd14;
	ld.global.nc.v4.f32 	{%f49, %f50, %f51, %f52}, [%rd36];
	add.f32 	%f57, %f44, %f52;
	add.f32 	%f58, %f43, %f51;
	add.f32 	%f59, %f42, %f50;
	add.f32 	%f60, %f41, %f49;
	add.s64 	%rd37, %rd34, %rd14;
	st.global.v4.f32 	[%rd37], {%f60, %f59, %f58, %f57};
	add.s32 	%r38, %r53, %r4;
	add.s32 	%r39, %r38, %r4;
	add.s64 	%rd38, %rd35, %rd14;
	ld.global.nc.v4.f32 	{%f61, %f62, %f63, %f64}, [%rd38];
	add.s64 	%rd39, %rd36, %rd14;
	ld.global.nc.v4.f32 	{%f69, %f70, %f71, %f72}, [%rd39];
	add.f32 	%f77, %f64, %f72;
	add.f32 	%f78, %f63, %f71;
	add.f32 	%f79, %f62, %f70;
	add.f32 	%f80, %f61, %f69;
	add.s64 	%rd40, %rd37, %rd14;
	st.global.v4.f32 	[%rd40], {%f80, %f79, %f78, %f77};
	add.s32 	%r40, %r39, %r4;
	add.s64 	%rd41, %rd38, %rd14;
	ld.global.nc.v4.f32 	{%f81, %f82, %f83, %f84}, [%rd41];
	add.s64 	%rd42, %rd39, %rd14;
	ld.global.nc.v4.f32 	{%f89, %f90, %f91, %f92}, [%rd42];
	add.f32 	%f97, %f84, %f92;
	add.f32 	%f98, %f83, %f91;
	add.f32 	%f99, %f82, %f90;
	add.f32 	%f100, %f81, %f89;
	add.s64 	%rd43, %rd40, %rd14;
	st.global.v4.f32 	[%rd43], {%f100, %f99, %f98, %f97};
	add.s32 	%r53, %r40, %r4;
	setp.lt.s32 	%p5, %r53, %r5;
	@%p5 bra 	$L__BB0_6;

$L__BB0_7:
	shl.b32 	%r15, %r5, 2;
	add.s32 	%r57, %r15, %r3;
	setp.ge.s32 	%p6, %r57, %r26;
	@%p6 bra 	$L__BB0_14;

	add.s32 	%r41, %r4, %r26;
	add.s32 	%r42, %r57, %r4;
	not.b32 	%r43, %r42;
	add.s32 	%r44, %r41, %r43;
	div.u32 	%r17, %r44, %r4;
	add.s32 	%r45, %r17, 1;
	and.b32  	%r56, %r45, 3;
	setp.eq.s32 	%p7, %r56, 0;
	@%p7 bra 	$L__BB0_11;

	add.s32 	%r46, %r2, %r15;
	add.s32 	%r47, %r46, %r1;
	mul.wide.s32 	%rd44, %r47, 4;
	add.s64 	%rd63, %rd1, %rd44;
	mul.wide.s32 	%rd16, %r4, 4;
	add.s64 	%rd62, %rd2, %rd44;
	add.s64 	%rd61, %rd3, %rd44;

$L__BB0_10:
	.pragma "nounroll";
	ld.global.nc.f32 	%f101, [%rd62];
	ld.global.nc.f32 	%f102, [%rd61];
	add.f32 	%f103, %f102, %f101;
	st.global.f32 	[%rd63], %f103;
	add.s32 	%r57, %r57, %r4;
	add.s64 	%rd63, %rd63, %rd16;
	add.s64 	%rd62, %rd62, %rd16;
	add.s64 	%rd61, %rd61, %rd16;
	add.s32 	%r56, %r56, -1;
	setp.ne.s32 	%p8, %r56, 0;
	@%p8 bra 	$L__BB0_10;

$L__BB0_11:
	setp.lt.u32 	%p9, %r17, 3;
	@%p9 bra 	$L__BB0_14;

	mul.wide.s32 	%rd25, %r4, 4;

$L__BB0_13:
	mul.wide.s32 	%rd45, %r57, 4;
	add.s64 	%rd46, %rd3, %rd45;
	add.s64 	%rd47, %rd2, %rd45;
	ld.global.nc.f32 	%f104, [%rd47];
	ld.global.nc.f32 	%f105, [%rd46];
	add.f32 	%f106, %f105, %f104;
	add.s64 	%rd48, %rd1, %rd45;
	st.global.f32 	[%rd48], %f106;
	add.s64 	%rd49, %rd46, %rd25;
	add.s64 	%rd50, %rd47, %rd25;
	ld.global.nc.f32 	%f107, [%rd50];
	ld.global.nc.f32 	%f108, [%rd49];
	add.f32 	%f109, %f108, %f107;
	add.s64 	%rd51, %rd48, %rd25;
	st.global.f32 	[%rd51], %f109;
	add.s32 	%r48, %r57, %r4;
	add.s32 	%r49, %r48, %r4;
	add.s64 	%rd52, %rd49, %rd25;
	add.s64 	%rd53, %rd50, %rd25;
	ld.global.nc.f32 	%f110, [%rd53];
	ld.global.nc.f32 	%f111, [%rd52];
	add.f32 	%f112, %f111, %f110;
	add.s64 	%rd54, %rd51, %rd25;
	st.global.f32 	[%rd54], %f112;
	add.s32 	%r50, %r49, %r4;
	add.s64 	%rd55, %rd52, %rd25;
	add.s64 	%rd56, %rd53, %rd25;
	ld.global.nc.f32 	%f113, [%rd56];
	ld.global.nc.f32 	%f114, [%rd55];
	add.f32 	%f115, %f114, %f113;
	add.s64 	%rd57, %rd54, %rd25;
	st.global.f32 	[%rd57], %f115;
	add.s32 	%r57, %r50, %r4;
	setp.lt.s32 	%p10, %r57, %r26;
	@%p10 bra 	$L__BB0_13;

$L__BB0_14:
	ret;

}

